{
    "logistic-regression-word-1_2-char-2_6": {
        "class": "LogisticRegressionBagOf",
        "params": {
            "model_params": {},
            "tokenizer_params": {
                "word": {
                    "ngram_range": [
                        1,
                        2
                    ],
                    "max_features": 5000
                },
                "char": {
                    "ngram_range": [
                        2,
                        6
                    ],
                    "max_features": 5000
                }
            },
            "training_params": {},
            "inference_params": {}
        }
    },
    "multilingual-dec-512-shots": {
        "class": "SymantoDualEncoder",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "paraphrase-multilingual-mpnet-base-v2",
                "label2text": {
                    "gpt-3.5-turbo-instruct": "This text has been generated by GPT-3.5.",
                    "gpt-4": "This text has been generated by GPT-4.",
                    "ai21.j2-ultra-v1": "This text has been generated by Jurassic.",
                    "meta-llama/Llama-2-70b-chat-hf": "This text has been generated by Llama2.",
                    "cohere.command-text-v14": "This text has been generated by Cohere.",
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": "This text has been generated by Mixtral."
                }
            },
            "tokenizer_params": {},
            "training_params": {
                "shots": 512,
                "batch_size": 4,
                "epochs": 5,
                "lr": 2e-5,
                "strategy": "default"
            },
            "inference_params": {}
        }
    },
    "multilingual-dec-zero-shot": {
        "class": "SymantoDualEncoder",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "paraphrase-multilingual-mpnet-base-v2",
                "label2text": {
                    "gpt-3.5-turbo-instruct": "This text has been generated by GPT-3.5.",
                    "gpt-4": "This text has been generated by GPT-4.",
                    "ai21.j2-ultra-v1": "This text has been generated by Jurassic.",
                    "meta-llama/Llama-2-70b-chat-hf": "This text has been generated by Llama2.",
                    "cohere.command-text-v14": "This text has been generated by Cohere.",
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": "This text has been generated by Mixtral."
                }
            },
            "tokenizer_params": {},
            "training_params": {
                "shots": 0
            },
            "inference_params": {}
        }
    },
    "xlm-roberta-large": {
        "class": "HuggingFaceClassifier",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "FacebookAI/xlm-roberta-large",
                "num_labels": 6,
                "id2label": {
                    "0": "gpt-3.5-turbo-instruct",
                    "1": "gpt-4",
                    "2": "ai21.j2-ultra-v1",
                    "3": "meta-llama/Llama-2-70b-chat-hf",
                    "4": "cohere.command-text-v14",
                    "5": "mistralai/Mixtral-8x7B-Instruct-v0.1"
                },
                "label2id": {
                    "gpt-4": 0,
                    "gpt-3.5-turbo-instruct": 1,
                    "ai21.j2-ultra-v1": 2,
                    "meta-llama/Llama-2-70b-chat-hf": 3,
                    "cohere.command-text-v14": 4,
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": 5
                }
            },
            "tokenizer_params": {
                "model_max_length": 512
            },
            "training_params": {
                "output_dir": "./checkpoints/subtask_2/xlm_roberta",
                "per_device_train_batch_size": 4,
                "num_train_epochs": 5,
                "learning_rate": 5e-5,
                "logging_steps": 20,
                "save_strategy": "no",
                "fp16": true,
                "auto_find_batch_size": true
            },
            "inference_params": {
                "output_dir": "./checkpoints/subtask_2/xlm_roberta",
                "per_device_eval_batch_size": 4
            }
        }
    },
    "mdeberta-v3-large": {
        "class": "HuggingFaceClassifier",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "microsoft/mdeberta-v3-base",
                "num_labels": 6,
                "id2label": {
                    "0": "gpt-3.5-turbo-instruct",
                    "1": "gpt-4",
                    "2": "ai21.j2-ultra-v1",
                    "3": "meta-llama/Llama-2-70b-chat-hf",
                    "4": "cohere.command-text-v14",
                    "5": "mistralai/Mixtral-8x7B-Instruct-v0.1"
                },
                "label2id": {
                    "gpt-4": 0,
                    "gpt-3.5-turbo-instruct": 1,
                    "ai21.j2-ultra-v1": 2,
                    "meta-llama/Llama-2-70b-chat-hf": 3,
                    "cohere.command-text-v14": 4,
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": 5
                }
            },
            "tokenizer_params": {
                "model_max_length": 512
            },
            "training_params": {
                "output_dir": "./checkpoints/subtask_2/mdeberta-v3-large",
                "per_device_train_batch_size": 4,
                "num_train_epochs": 5,
                "learning_rate": 5e-5,
                "logging_steps": 20,
                "save_strategy": "no",
                "fp16": true,
                "auto_find_batch_size": true
            },
            "inference_params": {
                "output_dir": "./checkpoints/subtask_2/mdeberta-v3-large",
                "per_device_eval_batch_size": 4
            }
        }
    },
    "mbart-large-50": {
        "class": "HuggingFaceClassifier",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "facebook/mbart-large-50",
                "num_labels": 6,
                "id2label": {
                    "0": "gpt-3.5-turbo-instruct",
                    "1": "gpt-4",
                    "2": "ai21.j2-ultra-v1",
                    "3": "meta-llama/Llama-2-70b-chat-hf",
                    "4": "cohere.command-text-v14",
                    "5": "mistralai/Mixtral-8x7B-Instruct-v0.1"
                },
                "label2id": {
                    "gpt-4": 0,
                    "gpt-3.5-turbo-instruct": 1,
                    "ai21.j2-ultra-v1": 2,
                    "meta-llama/Llama-2-70b-chat-hf": 3,
                    "cohere.command-text-v14": 4,
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": 5
                }
            },
            "tokenizer_params": {
                "model_max_length": 512
            },
            "training_params": {
                "output_dir": "./checkpoints/subtask_2/mbart-large-50",
                "per_device_train_batch_size": 4,
                "num_train_epochs": 5,
                "learning_rate": 5e-5,
                "logging_steps": 20,
                "save_strategy": "no",
                "fp16": true,
                "auto_find_batch_size": true
            },
            "inference_params": {
                "output_dir": "./checkpoints/subtask_2/mbart-large-50",
                "per_device_eval_batch_size": 4
            }
        }
    },
    "mt5-large": {
        "class": "HuggingFaceClassifier",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "google/mt5-large",
                "num_labels": 6,
                "id2label": {
                    "0": "gpt-3.5-turbo-instruct",
                    "1": "gpt-4",
                    "2": "ai21.j2-ultra-v1",
                    "3": "meta-llama/Llama-2-70b-chat-hf",
                    "4": "cohere.command-text-v14",
                    "5": "mistralai/Mixtral-8x7B-Instruct-v0.1"
                },
                "label2id": {
                    "gpt-4": 0,
                    "gpt-3.5-turbo-instruct": 1,
                    "ai21.j2-ultra-v1": 2,
                    "meta-llama/Llama-2-70b-chat-hf": 3,
                    "cohere.command-text-v14": 4,
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": 5
                }
            },
            "tokenizer_params": {
                "model_max_length": 512
            },
            "training_params": {
                "output_dir": "./checkpoints/subtask_2/mt5-large",
                "per_device_train_batch_size": 4,
                "num_train_epochs": 5,
                "learning_rate": 5e-5,
                "logging_steps": 20,
                "save_strategy": "no",
                "fp16": true,
                "auto_find_batch_size": true
            },
            "inference_params": {
                "output_dir": "./checkpoints/subtask_2/mt5-large",
                "per_device_eval_batch_size": 4
            }
        }
    },
    "me5-large": {
        "class": "HuggingFaceClassifier",
        "params": {
            "model_params": {
                "pretrained_model_name_or_path": "intfloat/multilingual-e5-large",
                "num_labels": 6,
                "id2label": {
                    "0": "gpt-3.5-turbo-instruct",
                    "1": "gpt-4",
                    "2": "ai21.j2-ultra-v1",
                    "3": "meta-llama/Llama-2-70b-chat-hf",
                    "4": "cohere.command-text-v14",
                    "5": "mistralai/Mixtral-8x7B-Instruct-v0.1"
                },
                "label2id": {
                    "gpt-4": 0,
                    "gpt-3.5-turbo-instruct": 1,
                    "ai21.j2-ultra-v1": 2,
                    "meta-llama/Llama-2-70b-chat-hf": 3,
                    "cohere.command-text-v14": 4,
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": 5
                }
            },
            "tokenizer_params": {
                "model_max_length": 512
            },
            "training_params": {
                "output_dir": "./checkpoints/subtask_2/me5-large",
                "per_device_train_batch_size": 4,
                "num_train_epochs": 5,
                "learning_rate": 5e-5,
                "logging_steps": 20,
                "save_strategy": "no",
                "fp16": true,
                "auto_find_batch_size": true
            },
            "inference_params": {
                "output_dir": "./checkpoints/subtask_2/me5-large",
                "per_device_eval_batch_size": 4
            }
        }
    }
}